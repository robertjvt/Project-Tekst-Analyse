- EXERCISE 1 -

1a:
[('Beryl', 'Coronet'), ('Black', 'Swan'), ('Catherine', 'Cusack'), ('Charing', 'Cross'), ('Count', 'Von'), ('Covent', 'Garden'), ('Ezekiah', 'Hopkins'), ('HEADED', 'LEAGUE'), ('Klux', 'Klan'), ('Ku', 'Klux'), ('Lancaster', 'Gate'), ('San', 'Francisco'), ('Spence', 'Munro'), ('Von', 'Kramm'), ('West', 'End'), ('Yours', 'faithfully'), ('carte', 'blanche'), ('equinoctial', 'gales'), ('moral', 'retrogression'), ('piteous', 'spectacle')]

1b:
[('Beryl', 'Coronet'), ('Briony', 'Lodge'), ('Copper', 'Beeches'), ('Covent', 'Garden'), ('Ezekiah', 'Hopkins'), ('HEADED', 'LEAGUE'), ('Klux', 'Klan'), ('Ku', 'Klux'), ('Lancaster', 'Gate'), ('San', 'Francisco'), ('Scotland', 'Yard'), ('Spence', 'Munro'), ('Swandam', 'Lane'), ('Von', 'Kramm'), ('West', 'End'), ('Yours', 'faithfully'), ('carte', 'blanche'), ('equinoctial', 'gales'), ('moral', 'retrogression'), ('piteous', 'spectacle')]

1c:
[(',', 'and'), ('."', '"'), ('.', '"'), ('of', 'the'), ('.', 'I'), ('in', 'the'), ('?"', '"'), ("'", 's'), ('"', 'I'), (',', 'I'), (',', 'but'), ('I', 'have'), ('to', 'the'), (',"', 'said'), ('Mr', '.'), ('.', 'It'), ('that', 'I'), ('at', 'the'), ('.', 'The'), ('and', 'I')]

Explanation: PMI measures how often a bigram appears in relation to its unigrams. Chi-square measures how likely it is that a bigram appears but also how often it doesn't  appear in relation to the expected amount. This can (and in this case does) lead to slightly different results

1d:
Spearmanâ€™s coefficient: 0.9573529411764706

- EXERCISE 2 -
1.
Penn Treebank:
Peter/NNP really/RB liked/VBN the/DT movies/NNS and/CC warm/JJ pop-corn/NN . He/PRP would/MD never/RB bring/VB Mira/NNP with/IN him/PRP , though/IN .

Brown Corpus:
Peter/NP really/RB liked/VBD the/AT movies/NNS and/CC warm/JJ pop-corn/NN . He/PPS would/MD never/RB bring/VB Mira/NP with/IN him/PPO , though/CS .

NLTK's universal:
Peter/NOUN really/ADV liked/VERB the/DET movies/NOUN and/CONJ warm/ADJ pop-corn/NOUN . He/PRON would/VERB never/ADV bring/VERB Mira/NOUN with/ADP him/PRON , though/ADP .

2.
a) How many words and sentences are there?
Words: 57169
Sentences: 3886

b) What is the 50th word and its POS? How about the 75th?
('grim', 'JJ')
('from', 'IN')

c) How many different POS tags are represented in this Brown category?
169

d) What are the top 15 words and their counts?
[('.', 3326), (',', 2805), ('the', 2573), ('to', 1284), ('and', 1215), ('a', 1136), ('of', 903), ('was', 820), ('``', 740), ("''", 738), ('he', 670), ('?', 664), ('in', 658), ('I', 583), ('his', 529)]

e) What are the top 15 POS tags and their counts?
[('NN', 6461), ('IN', 4692), ('.', 4322), ('AT', 4321), (',', 2805), ('VBD', 2645), ('RB', 2459), ('JJ', 2109), ('VB', 2026), ('PPS', 1767), ('NP', 1737), ('CC', 1692), ('NNS', 1435), ('PPO', 1207), ('VBN', 1161)]

f) What are the most frequent POS tag in the 20th sentence? And in the 40th?
sentence 20 (index 19): [('PPSS+BER', 1), ('*', 1), ('AT', 1), ('NN', 1), ('TO', 1), ('VB', 1), ('JJ', 1), ('.', 1)]
sentence 40 (index 39): [('PPSS', 1), ('VBD', 1), ('TO', 1), ('VB', 1), ('IN', 1), ('NN', 1), (',', 1), ('RB', 1), ("''", 1), ('--', 1)]


g) What is the most frequent adverb?
('back', 119)

h) What is the most frequent adjective?
('old', 58)

i) What POS can the word 'so' be used for?
[('QL', 43), ('RB', 35), ('CS', 26)]

j) What is the most frequent POS tag for 'so'?
('QL', 43)

k) For each 'so' tag, give an example.
[[("We've", 'PPSS+HV'), ('always', 'RB'), ('been', 'BEN'), ('so', 'QL'), ('close', 'JJ'), ("''", "''"), ('.', '.')],
[("I'll", 'PPSS+MD'), ('bet', 'VB'), ('he', 'PPS'), ("wouldn't", 'MD*'), ('be', 'BE'), ('pleased', 'VBN'), ('if', 'CS'), ('a', 'AT'), ('rumdum', 'NN'), ('like', 'CS'), ('me', 'PPO'), ('were', 'BED'), ('to', 'TO'), ('ask', 'VB'), ('his', 'PP$'), ('daughter', 'NN'), ('for', 'IN'), ('a', 'AT'), ('date', 'NN'), ('--', '--'), ('I', 'PPSS'), ('mean', 'VB'), (',', ','), ('after', 'CS'), ("I'm", 'PPSS+BEM'), ('out', 'IN'), ('of', 'IN'), ('the', 'AT'), ('hospital', 'NN'), (',', ','), ('a', 'AT'), ('month', 'NN'), ('or', 'CC'), ('so', 'RB'), ('from', 'IN'), ('now', 'RB'), ("''", "''"), ('.', '.')],
[('I', 'PPSS'), ('put', 'VB'), ('in', 'RP'), ('new', 'JJ'), ('batteries', 'NNS'), ('so', 'CS'), ('as', 'CS'), ('to', 'TO'), ('be', 'BE'), ('certain', 'JJ'), ("I'd", 'PPSS+MD'), ('have', 'HV'), ('plenty', 'NN'), ('of', 'IN'), ('power', 'NN'), ('and', 'CC'), ('on', 'IN'), ('my', 'PP$'), ('way', 'NN'), ('out', 'RP'), ('walked', 'VBD'), ('over', 'RP'), ('to', 'IN'), ('the', 'AT'), ('regular', 'JJ'), ('parking', 'VBG'), ('stalls', 'NNS'), ('and', 'CC'), ('stood', 'VBD'), ('looking', 'VBG'), ('at', 'IN'), ('them', 'PPO'), ('thoughtfully', 'RB'), ('.', '.')]]

l) For each 'so's POS, find out the most likely preceding and following POS.
preceding: (',', 14)
following: ('JJ', 17)

3.
First 20 POS tags
('THE', 'DT')
('ADVENTURES', 'NNP')
('OF', 'NNP')
('SHERLOCK', 'NNP')
('HOLMES', 'NNP')
('by', 'IN')
('SIR', 'NNP')
('ARTHUR', 'NNP')
('CONAN', 'NNP')
('DOYLE', 'NNP')
('I', 'PRP')
('.', '.')
('A', 'DT')
('Scandal', 'NNP')
('in', 'IN')
('Bohemia', 'NNP')
('II', 'NNP')
('.', '.')
('The', 'DT')
('Red-headed', 'JJ')
... 

4.
In the code I used a PMI function to see the association of the POS tags.
I used PMI, as this gives a good overview of association of independent POS
tags and we didn't have any expected expected probabilities.
Code output:

Top 5 PMI scores:
((')', ':'), 5.851377341367533)
(('(', 'CD'), 4.877431233015493)
(('NNP', '('), 4.609066414543538)
(('``', "''"), 4.530353231228558)
(('MD', 'VB'), 4.432612179938715)

Top 5 raw frequencies:
(('DT', 'NN'), 5986)
(('IN', 'DT'), 4823)
(('IN', 'PRP'), 3889)
(('NN', 'IN'), 3755)
(('PRP', '$'), 3277)

It looks interesting, although it might be more interesting to look at the top
10 or the top 20 PMI scores, as the top 5 mainly contain punctuation. If we
filter that out or look at more PMI scores, we could have some interesting
results.

The PMI scores differ a lot from the raw frequencies. I think some of the PMI
scores also indicate the syntax of the text e.g. '(', 'CD', which might be a
chapter number or something along those lines. The raw frequencies only have
combinations of actual words (except the last one). Although the examples in
the raw frequencies appear more frequently, they have a lower probability of
occuring together.

They could be used to analyse the syntax of a text. This might be useful for
comparing the syntax of texts from different time periods, texts written in
different dialects or texts written for different audiences (e.g. for children
vs for university students).
